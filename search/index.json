[{"content":"\nIntroduction Yesterday I had the privillege of speaking at a tech conference for the first time! My colleague Eduard Keilholz pushed me to answer the call for papers and get started with speaking about cool tech at conferences. To my big surprise, my session was accepted and could take this next step in my career!\nMy session During the work for 4Dotnet, I work for one of our customers where we are actively implementing microservices using .NET, Dapr and Azure Container Apps. In the local development environments, we use .NET Aspire to quickly gain insights into what the services are doing. OpenTelemetry is the key to discovering potential issues with the services before they occur in production.\nWith this experience, the idea for the session was born. How can I teach developers to build a good local development environment for distributed applications?\nSlides Interested in the slides? I got you covered! Click here to download the slides.\nCode Of course the code that I used to build the demo is also available. Click here to be taken to the Github repository. Do you have any questions? No problem, I\u0026rsquo;m happy to help you out and get started using Dapr and Aspire. Just open a Github issue here and we\u0026rsquo;ll be in touch!\n","date":"2024-04-18T16:00:00+02:00","permalink":"https://fvandillen.github.io/posts/speaking-at-futuretech-2024/","title":"Speaking at Futuretech 2024"},{"content":"Introduction For one of our customers we are in the process of rebuilding the frontend due to growth in the IT organization. In the past year or two, the single team of developers responsible for frontend development has grown into a more feature-oriented organization. This means that one feature can be owned by team A and another feature can be owned by team B. This creates challenges when working on a single frontend that contains legacy as well.\nFor instance, the current application can only be deployed as a whole. This means releases of new versions have to be coordinated between the different teams. This makes releasing more labour intensive than it should be.\nAlso testing is an issue. Ideally you want to run automated UI tests so you are certain the frontend behaves in the way you expect it to. However when you have to run the entire test suite (which takes 3+ hours) when you change a single comma, this becomes an issue when you want to release quick and often.\nMicrofrontends as a solution Luckily, we have tools at our disposal nowadays to overcome these issues. One of the methods is called microfrontends. When going this route, you essentially create a shell application that will be responsible for loading the microfrontends (or MFEs) and routing the user to the correct MFE. The shell also functions as a coordination layer between the MFEs and will address any cross-cutting concerns such as authentication and translations.\nIn our case the shell application will be written in Vue 3. This Javascript framework is widely used at our customer and most developers are familiar with it already. The plan they drafted was to expose the current Vue 2 application as an MFE and consume it in the new shell application. This will allow the teams to gradually recreate those pages and features in more modern web technology and eventually get rid of the old Vue 2 application entirely.\nThe major upside of having multiple MFEs is that we can now have multiple teams working on them! Each team has their own repositories and pipelines which means they can deploy and test independently.\nModule federation So how can we expose our MFEs to the shell application and consume them? To achieve this, we decided to use an approach called module federation. In essence, this allows us to remotely load Javascript modules from a URL and mount them into our shell. Because the modules are fetched remotely every time the shell launches, they can be deployed independently.\nHowever, this has proven to not be a very easy task. For one, the shell runs Vue 3 which means you cannot (easily) mount Vue 2 components inside it. In the first iteration, we tried to wrap our Vue 2 components with all of their dependencies before exposing it to the shell via module federation. This quickly became messy and didn\u0026rsquo;t work well:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 export function bootstrapComponentRemote(WrapperComponent: any, wrapperId: string) { // Get a correctly bootstrapped Vue instance with dependencies configured. const vueInstance = bootstrapComponent(WrapperComponent); // Overwrite the render method with our own logic. vueInstance.render = (x) =\u0026gt; { return x(WrapperComponent, { on: this.$attrs, attrs: this.$attrs, props: this.$props, scopedSlots: this.$scopedSlots }) }; // Return the Vue2 instance with our Vue2 component wrapped as a Vue3 component. return { mounted() { vueInstance.$mount(`#${wrapperId}`); }, props: WrapperComponent.props, render() { vueInstance \u0026amp;\u0026amp; vueInstance.$forceUpdate(); }, }; } The above approach worked fine when initially routing to the remote component, but subsequent routing would result in the component not being rendered at all. Oops! Quite a big deal when you\u0026rsquo;re working with a single page application\u0026hellip;\nWeb components to the rescue! What if we didn\u0026rsquo;t have to deal with all the UI framework complexities and could just send a standardized (and even native) module to our shell? That sounds like black magic, but fortunately the tech is already here. It\u0026rsquo;s called web components and all the major browsers already support it. The tech is based on open standards and uses ES modules to wire it all together.\nEssentially, this turns any module/component into a reusable piece of Javascript that we can then use in any framework or even in plain HTML if that is your cup of tea. Think of it as Docker containers for the World Wide Web. ðŸ˜ŽðŸ˜Ž\nWhat we did is wrap the Vue 2 component as a web component before exposing it via module federation. To achieve this, we use the plugin Vue web component wrapper. This plugin allows us to easily wrap any Vue 2 component as a web component:\n1 2 3 4 5 6 7 8 import Vue from \u0026#39;vue\u0026#39; import wrap from \u0026#39;@vue/web-component-wrapper\u0026#39; const Component = { // any component options } const CustomElement = wrap(Vue, Component); The wrapped component is exposed via module federation (more on that in part 2 of these series). Once the module is consumed in the shell, it can be registered as a custom element:\n1 2 import CustomElement from \u0026#39;mfe/customElement\u0026#39;; window.customElements.define(\u0026#39;my-element\u0026#39;, CustomElement) Once registered, a new wrapper component can be made in the shell that contains a template that uses the custom element:\n1 2 3 \u0026lt;template\u0026gt; \u0026lt;my-element\u0026gt;\u0026lt;/my-element\u0026gt; \u0026lt;/template\u0026gt; Conclusion The custom element behaves exactly like it should. It can be routed to, attributes can be added to it as a means of passing arguments. Events can be emitted by it and the browser tools can be used to fully inspect it. The web component achieves full encapsulation from the DOM by using a shadow DOM. Therefore it is (partly) immune from specific CSS styles that affect the regular DOM.\nAll in all, this provides us with a very nice way of exposing our legacy components with the use of open standards. We are not limited by specific frameworks and could even use React or Angular components in the shell. This creates a very solid foundation for the rest of our adventures with our customer.\nI intend to continue writing about this and will go in-depth on module federation in a next installment. Stay tuned!\n","date":"2023-01-10T19:00:00+01:00","permalink":"https://fvandillen.github.io/posts/microfrontends-web-components-part-1/","title":"Microfrontends: Web components (part 1)"},{"content":"When working on a .NET project, you are highly likely to use custom objects. When you start debugging your code, you can see them in the debugger. However, the default way these objects are displayed by the debugger is not very handy nor developer friendly. You are probably interested in the identifying properties of your custom object rather than the name of your class.\nExample program Note: The example program is using top-level statements, so you will not see any namespaces or method body. To learn more, check out: https://docs.microsoft.com/en-us/dotnet/csharp/whats-new/tutorials/top-level-statements\nConsider the following program: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 var niceCustomObject = new CustomObject(\u0026#34;4Dotnet\u0026#34;, \u0026#34;Super cool description.\u0026#34;); var anotherNiceCustomObject = new CustomObject(\u0026#34;Microsoft\u0026#34;, \u0026#34;Another description.\u0026#34;); Console.WriteLine(\u0026#34;Hello, World!\u0026#34;); public class CustomObject { public string Name { get; set; } public string Description { get; set; } public CustomObject(string name, string description) { Name = name; Description = description; } } When you set a breakpoint on line 4, the custom object will be displayed in the debugger like this:\nThat isn\u0026rsquo;t helping! It would be much nicer to see the name of the custom object right away, so we can easily distinguish between different objects of the same kind.\nImplementing the DebuggerDisplayAttribute Lucky for us, we can use the DebuggerDisplayAttribute available in .NET. We can put it above our class and provide a string argument containing the template we want to use for displaying object instances in the debugger. The string is evaluated as the name of a field, property, or method.\nIn our case, we use the Name field so we can easily identify each object instance.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 using System.Diagnostics; var niceCustomObject = new CustomObject(\u0026#34;4Dotnet\u0026#34;, \u0026#34;Super cool description.\u0026#34;); var anotherNiceCustomObject = new CustomObject(\u0026#34;Microsoft\u0026#34;, \u0026#34;Another description with a different text.\u0026#34;); Console.WriteLine(\u0026#34;Hello, World!\u0026#34;); [DebuggerDisplay(\u0026#34;{Name}\u0026#34;)] public class CustomObject { public string Name { get; set; } public string Description { get; set; } public CustomObject(string name, string description) { Name = name; Description = description; } } And no surprise here, we can now see the value appear in the debugger:\nConclusion Using this simple attribute, we can debug complex classes much easier by simply telling the debugger how we want it to display objects. To learn more about the specifics of the DebuggerDisplayAttribute, check out: https://docs.microsoft.com/en-us/visualstudio/debugger/using-the-debuggerdisplay-attribute?view=vs-2022\n","date":"2022-07-01T09:01:27+02:00","permalink":"https://fvandillen.github.io/posts/level-up-your-debugging-game/","title":"Level up your debugging game!"},{"content":"Introduction Sometimes a query in Synapse serverless SQL doesn\u0026rsquo;t work as expected and times out, or worse. It may happen that it gets stuck entirely. Luckily, there is a way to get things going again! Here\u0026rsquo;s how.\nIn your favorite SQL tool, run the following query to identify the process ID of the stuck query:\nSQL snippet 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 SELECT \u0026#39;Running\u0026#39; as [Status], Transaction_id as [Request ID], \u0026#39;SQL On-demand\u0026#39; as [SQL Resource], s.login_name as [Submitter], s.Session_Id as [Session ID], req.start_time as [Submit time], req.command as [Request Type], SUBSTRING( sqltext.text, (req.statement_start_offset/2)+1, ( ( CASE req.statement_end_offset WHEN -1 THEN DATALENGTH(sqltext.text) ELSE req.statement_end_offset END - req.statement_start_offset )/2 ) + 1 ) as [Query Text], req.total_elapsed_time as [Duration] FROM sys.dm_exec_requests req CROSS APPLY sys.dm_exec_sql_text(sql_handle) sqltext JOIN sys.dm_exec_sessions s ON req.session_id = s.session_id Killing the process Using your obtained process ID (in this example it will be 81), run the following SQL to kill the process: 1 KILL 81 Be warned, this might take a while. If everything went well, you will have things moving again.\nWhat if this doesn\u0026rsquo;t work? It could be that things are unable to get started again. In that case, you will have one more trick in the book: Azure support. If you open a ticket with them, they can restart your SQL serverless pool.\n","date":"2022-06-30T13:56:48+02:00","permalink":"https://fvandillen.github.io/posts/how-to-kill-a-synapse-query/","title":"How to kill a Synapse query"}]